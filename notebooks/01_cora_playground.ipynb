{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cd88cef-b11a-419f-8492-160a7831ab99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.4.1\n",
      "pyg: 2.6.1\n",
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Purpose: import packages, set device, set a reproducible seed, print versions\n",
    "\n",
    "import os, time, math, random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Reproducibility\n",
    "def set_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"torch: {torch.__version__}\")\n",
    "try:\n",
    "    import torch_geometric as tg\n",
    "    print(f\"pyg: {tg.__version__}\")\n",
    "except Exception as e:\n",
    "    print(\"pyg import error:\", e)\n",
    "\n",
    "print(\"device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "343cff3a-88b5-4c5e-9679-041d0bd82987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cora()\n",
      "Nodes: 2708  | Edges (directed count): 10556  | Feats: 1433 | Classes: 7\n",
      "Undirected unique edges: 5278\n",
      "Splits: train=140, val=500, test=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Purpose: download Cora via PyG and report core stats\n",
    "\n",
    "DATA_ROOT = \"./data\"\n",
    "dataset = Planetoid(root=DATA_ROOT, name=\"Cora\")\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "def report_data_summary(d):\n",
    "    # undirected unique edges count\n",
    "    ei = d.edge_index.cpu().numpy()\n",
    "    undirected = set()\n",
    "    for u, v in zip(ei[0], ei[1]):\n",
    "        if u == v:\n",
    "            continue\n",
    "        a, b = (int(u), int(v)) if u < v else (int(v), int(u))\n",
    "        undirected.add((a, b))\n",
    "\n",
    "    print(\"Cora()\")\n",
    "    print(f\"Nodes: {d.num_nodes}  | Edges (directed count): {d.edge_index.size(1)}  | Feats: {d.x.size(1)} | Classes: {dataset.num_classes}\")\n",
    "    print(f\"Undirected unique edges: {len(undirected)}\")\n",
    "    print(f\"Splits: train={int(d.train_mask.sum())}, val={int(d.val_mask.sum())}, test={int(d.test_mask.sum())}\")\n",
    "\n",
    "report_data_summary(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6264cbcf-b666-456c-b661-8401a113dabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: helper functions for Largest Connected Component percent and accuracy\n",
    "\n",
    "def lcc_percent(d):\n",
    "    G = to_networkx(d, to_undirected=True)\n",
    "    comps = list(nx.connected_components(G))\n",
    "    if not comps:\n",
    "        return 0.0, 0\n",
    "    lcc = max(comps, key=len)\n",
    "    return 100.0 * len(lcc) / d.num_nodes, len(comps)\n",
    "\n",
    "@torch.no_grad()\n",
    "def accuracy(logits, y, mask):\n",
    "    pred = logits.argmax(dim=-1)\n",
    "    correct = (pred[mask] == y[mask]).float().mean().item() if mask.sum() > 0 else 0.0\n",
    "    return correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39600d15-f23e-424b-9698-5165ddef5d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: define a simple 2-layer GCN and a trainer that times epochs and returns metrics\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_dim, hid_dim)\n",
    "        self.conv2 = GCNConv(hid_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "def train_model(model, d, epochs=200, lr=0.01, wd=5e-4, log_every=20):\n",
    "    model = model.to(device)\n",
    "    d = d.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    epoch_times = []\n",
    "    best_val = -1.0\n",
    "    best_snap = None\n",
    "    t0 = time.time()\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        t_ep0 = time.time()\n",
    "        model.train()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        out = model(d.x, d.edge_index)\n",
    "        loss = F.cross_entropy(out[d.train_mask], d.y[d.train_mask])\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(d.x, d.edge_index)\n",
    "            acc_train = accuracy(out, d.y, d.train_mask)\n",
    "            acc_val   = accuracy(out, d.y, d.val_mask)\n",
    "            acc_test  = accuracy(out, d.y, d.test_mask)\n",
    "\n",
    "        if acc_val > best_val:\n",
    "            best_val = acc_val\n",
    "            best_snap = dict(train=acc_train, val=acc_val, test=acc_test)\n",
    "\n",
    "        t_ep = time.time() - t_ep0\n",
    "        epoch_times.append(t_ep)\n",
    "\n",
    "        if ep == 1 or ep % log_every == 0 or ep == epochs:\n",
    "            print(f\"Epoch {ep:03d} | Loss {loss.item():.3f} | Train {acc_train:.3f} Val {acc_val:.3f} Test {acc_test:.3f}\")\n",
    "\n",
    "    total_time = time.time() - t0\n",
    "    avg_epoch_time = float(np.mean(epoch_times)) if epoch_times else 0.0\n",
    "\n",
    "    result = dict(\n",
    "        train=best_snap[\"train\"],\n",
    "        val=best_snap[\"val\"],\n",
    "        test=best_snap[\"test\"],\n",
    "        epochs=epochs,\n",
    "        train_time=total_time,\n",
    "        avg_epoch_time=avg_epoch_time,\n",
    "        best_val=best_val\n",
    "    )\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a66e3821-9717-4cbd-967e-d96ff3a6f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: utilities to work with undirected edges and build new edge_index\n",
    "\n",
    "def unique_undirected(edge_index):\n",
    "    ei = edge_index.detach().cpu().numpy()\n",
    "    S = set()\n",
    "    for u, v in zip(ei[0], ei[1]):\n",
    "        if u == v:\n",
    "            continue\n",
    "        a, b = (int(u), int(v)) if u < v else (int(v), int(u))\n",
    "        S.add((a, b))\n",
    "    return list(S)\n",
    "\n",
    "def build_edge_index_from_undirected(edge_pairs, device):\n",
    "    e = []\n",
    "    for u, v in edge_pairs:\n",
    "        e.append([u, v])\n",
    "        e.append([v, u])\n",
    "    if len(e) == 0:\n",
    "        # avoid empty tensor shape issues\n",
    "        return torch.empty((2, 0), dtype=torch.long, device=device)\n",
    "    return torch.tensor(e, dtype=torch.long, device=device).t().contiguous()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb9c7c7a-f0cf-40cc-b6ba-54d098722bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: compute edge scores for trimming using either Jaccard or Cosine\n",
    "\n",
    "def neighbor_sets(d):\n",
    "    n = d.num_nodes\n",
    "    N = [set() for _ in range(n)]\n",
    "    ei = d.edge_index.detach().cpu().numpy()\n",
    "    for u, v in zip(ei[0], ei[1]):\n",
    "        if u == v:\n",
    "            continue\n",
    "        uu, vv = int(u), int(v)\n",
    "        N[uu].add(vv)\n",
    "        N[vv].add(uu)\n",
    "    return N\n",
    "\n",
    "def jaccard_scores(d, edges_u):\n",
    "    N = neighbor_sets(d)\n",
    "    out = []\n",
    "    for u, v in edges_u:\n",
    "        Nu, Nv = N[u], N[v]\n",
    "        denom = len(Nu | Nv)\n",
    "        s = 0.0 if denom == 0 else len(Nu & Nv) / denom\n",
    "        out.append((s, u, v))\n",
    "    out.sort(reverse=True, key=lambda x: x[0])\n",
    "    return out\n",
    "\n",
    "def cosine_scores(d, edges_u):\n",
    "    X = d.x.detach().cpu().numpy().astype(np.float32)\n",
    "    norms = np.linalg.norm(X, axis=1)\n",
    "    out = []\n",
    "    for u, v in edges_u:\n",
    "        nu, nv = norms[u], norms[v]\n",
    "        s = 0.0 if (nu == 0.0 or nv == 0.0) else float(np.dot(X[u], X[v]) / (nu * nv))\n",
    "        out.append((s, u, v))\n",
    "    out.sort(reverse=True, key=lambda x: x[0])\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c27f8423-cb37-49c2-9330-b3895bcd5cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: trim edges by top-K score, preserve hubs if needed, reconnect components once to the LCC\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def degree_from_edges(edges_u, n):\n",
    "    d = np.zeros(n, dtype=np.int64)\n",
    "    for u, v in edges_u:\n",
    "        d[u] += 1\n",
    "        d[v] += 1\n",
    "    return d\n",
    "\n",
    "def trim_with_guards(\n",
    "    d,\n",
    "    method=\"cosine\",            # 'cosine' or 'jaccard'\n",
    "    keep_rate=0.80,             # fraction of undirected edges to keep\n",
    "    hub_percent=0.10,           # fraction of top-degree nodes to protect\n",
    "    reconnect_mode=\"bridge_once\",  # currently only one reconnection per component\n",
    "    effective_keep_cap=None     # optional cap on effective keep (e.g., 0.83)\n",
    "):\n",
    "    t0 = time.time()\n",
    "    n = d.num_nodes\n",
    "    edges_u = unique_undirected(d.edge_index)\n",
    "    E = len(edges_u)\n",
    "    target = max(1, int(E * keep_rate))\n",
    "\n",
    "    # score\n",
    "    if method == \"cosine\":\n",
    "        scored = cosine_scores(d, edges_u)\n",
    "    elif method == \"jaccard\":\n",
    "        scored = jaccard_scores(d, edges_u)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown method\")\n",
    "\n",
    "    kept = scored[:target]\n",
    "    removed = scored[target:]\n",
    "\n",
    "    kept_set = set((u, v) if u < v else (v, u) for _, u, v in kept)\n",
    "\n",
    "    # hub preserve: ensure top-degree nodes are not left with degree 0 in kept_set\n",
    "    deg0 = degree_from_edges(edges_u, n)\n",
    "    H = max(0, int(n * hub_percent))\n",
    "    hub_ids = np.argsort(-deg0)[:H] if H > 0 else []\n",
    "\n",
    "    removed_by_node = defaultdict(list)\n",
    "    for s, u, v in removed:\n",
    "        a, b = (u, v) if u < v else (v, u)\n",
    "        removed_by_node[u].append((s, a, b))\n",
    "        removed_by_node[v].append((s, a, b))\n",
    "\n",
    "    kept_deg = np.zeros(n, dtype=np.int64)\n",
    "    for (u, v) in kept_set:\n",
    "        kept_deg[u] += 1\n",
    "        kept_deg[v] += 1\n",
    "\n",
    "    for h in hub_ids:\n",
    "        if kept_deg[h] == 0 and removed_by_node[h]:\n",
    "            s, a, b = max(removed_by_node[h], key=lambda t: t[0])\n",
    "            if (a, b) not in kept_set:\n",
    "                kept_set.add((a, b))\n",
    "                kept_deg[a] += 1\n",
    "                kept_deg[b] += 1\n",
    "\n",
    "    # reconnect each non-LCC component once if possible\n",
    "    if reconnect_mode == \"bridge_once\":\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(range(n))\n",
    "        G.add_edges_from(list(kept_set))\n",
    "        comps = list(nx.connected_components(G))\n",
    "        if len(comps) > 1:\n",
    "            lcc = max(comps, key=len)\n",
    "            L = set(lcc)\n",
    "            for comp in comps:\n",
    "                if comp is lcc:\n",
    "                    continue\n",
    "                best = None\n",
    "                for x in comp:\n",
    "                    for s, a, b in removed_by_node.get(x, []):\n",
    "                        if ((a in comp and b in L) or (b in comp and a in L)) and ((a, b) not in kept_set):\n",
    "                            if (best is None) or (s > best[0]):\n",
    "                                best = (s, a, b)\n",
    "                if best is not None:\n",
    "                    _, a, b = best\n",
    "                    kept_set.add((a, b))\n",
    "                    G.add_edge(a, b)\n",
    "\n",
    "    # optional cap to avoid too much inflation\n",
    "    if effective_keep_cap is not None:\n",
    "        cap_edges = int(E * effective_keep_cap)\n",
    "        if len(kept_set) > cap_edges:\n",
    "            # drop the lowest score non-bridge edges until meeting cap\n",
    "            # build score map\n",
    "            score_map = {}\n",
    "            for s, u, v in scored:\n",
    "                a, b = (u, v) if u < v else (v, u)\n",
    "                if (a, b) not in score_map:\n",
    "                    score_map[(a, b)] = s\n",
    "\n",
    "            G = nx.Graph()\n",
    "            G.add_nodes_from(range(n))\n",
    "            G.add_edges_from(list(kept_set))\n",
    "\n",
    "            # recompute bridges to avoid breaking connectivity further\n",
    "            bridges = set(nx.bridges(G))\n",
    "\n",
    "            # sort edges ascending by score\n",
    "            candidates = sorted([e for e in kept_set if e not in bridges], key=lambda e: score_map.get(e, -1.0))\n",
    "            for a, b in candidates:\n",
    "                if len(kept_set) <= cap_edges:\n",
    "                    break\n",
    "                if G.has_edge(a, b):\n",
    "                    G.remove_edge(a, b)\n",
    "                    kept_set.remove((a, b))\n",
    "\n",
    "    new_edge_index = build_edge_index_from_undirected(list(kept_set), d.edge_index.device)\n",
    "    trim_time = time.time() - t0\n",
    "\n",
    "    # make a Data just to compute LCC% and components\n",
    "    tmp = type(data)(\n",
    "        x=d.x, y=d.y, edge_index=new_edge_index,\n",
    "        train_mask=d.train_mask, val_mask=d.val_mask, test_mask=d.test_mask\n",
    "    ).cpu()\n",
    "    lccp, comps = lcc_percent(tmp)\n",
    "\n",
    "    stats = dict(\n",
    "        orig_undirected=E,\n",
    "        kept_undirected=len(kept_set),\n",
    "        keep_rate_target=keep_rate,\n",
    "        keep_rate_effective=len(kept_set) / E,\n",
    "        LCC_percent=lccp,\n",
    "        components=comps\n",
    "    )\n",
    "    return new_edge_index, trim_time, stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de4d5074-c857-47c8-aec4-5810e0c52e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params set. METHOD: cosine | K_KEEP: 0.8 | HUB_P: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Purpose: define one place for all knobs used by the next cells\n",
    "\n",
    "# Trimming method and guards\n",
    "METHOD   = \"cosine\"       # 'cosine' or 'jaccard'\n",
    "K_KEEP   = 0.80           # target keep-rate on undirected edges (e.g., 0.90, 0.80, 0.70)\n",
    "HUB_P    = 0.10           # fraction of top-degree nodes to protect (0.05 or 0.10 worked well)\n",
    "RECONNECT= \"bridge_once\"  # reconnection strategy\n",
    "EFF_CAP  = None           # optional: e.g. 0.83 to cap effective keep if reconnect inflates too much\n",
    "\n",
    "# Model and training\n",
    "HIDDEN   = 64\n",
    "DROPOUT  = 0.5\n",
    "EPOCHS   = 200\n",
    "LR       = 0.01\n",
    "WD       = 5e-4\n",
    "\n",
    "print(\"Params set. METHOD:\", METHOD, \"| K_KEEP:\", K_KEEP, \"| HUB_P:\", HUB_P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fcfa0cd-42a2-4b5b-953d-b28effbabfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCC% (original): (91.76514032496307, 78)\n",
      "Epoch 001 | Loss 1.942 | Train 0.821 Val 0.516 Test 0.540\n",
      "Epoch 020 | Loss 0.012 | Train 1.000 Val 0.768 Test 0.783\n",
      "Epoch 040 | Loss 0.012 | Train 1.000 Val 0.768 Test 0.791\n",
      "Epoch 060 | Loss 0.018 | Train 1.000 Val 0.770 Test 0.800\n",
      "Epoch 080 | Loss 0.013 | Train 1.000 Val 0.752 Test 0.801\n",
      "Epoch 100 | Loss 0.012 | Train 1.000 Val 0.768 Test 0.806\n",
      "Epoch 120 | Loss 0.010 | Train 1.000 Val 0.760 Test 0.810\n",
      "Epoch 140 | Loss 0.012 | Train 1.000 Val 0.764 Test 0.810\n",
      "Epoch 160 | Loss 0.010 | Train 1.000 Val 0.770 Test 0.814\n",
      "Epoch 180 | Loss 0.012 | Train 1.000 Val 0.770 Test 0.806\n",
      "Epoch 200 | Loss 0.011 | Train 1.000 Val 0.764 Test 0.810\n",
      "\n",
      "BASELINE (GCN on original)\n",
      "train: 1.0000\n",
      "val: 0.7920\n",
      "test: 0.8080\n",
      "epochs: 200\n",
      "train_time: 2.6057\n",
      "avg_epoch_time: 0.0130\n",
      "best_val: 0.7920\n"
     ]
    }
   ],
   "source": [
    "# Purpose: train a baseline GCN on the original graph and record timings and accuracy\n",
    "\n",
    "set_seed(0)\n",
    "print(\"LCC% (original):\", lcc_percent(data))\n",
    "\n",
    "baseline_model = GCN(dataset.num_node_features, HIDDEN, dataset.num_classes, DROPOUT)\n",
    "base = train_model(baseline_model, data, epochs=EPOCHS, lr=LR, wd=WD, log_every=20)\n",
    "\n",
    "print(\"\\nBASELINE (GCN on original)\")\n",
    "for k, v in base.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcee1741-8693-448d-9b6f-b694e7773e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trim stats: {'orig_undirected': 5278, 'kept_undirected': 4358, 'keep_rate_target': 0.8, 'keep_rate_effective': 0.8256915498294809, 'LCC_percent': 90.76809453471196, 'components': 105} | trim_time: 0.04s\n",
      "Epoch 001 | Loss 1.942 | Train 0.843 Val 0.534 Test 0.547\n",
      "Epoch 020 | Loss 0.012 | Train 1.000 Val 0.740 Test 0.758\n",
      "Epoch 040 | Loss 0.008 | Train 1.000 Val 0.744 Test 0.758\n",
      "Epoch 060 | Loss 0.013 | Train 1.000 Val 0.750 Test 0.771\n",
      "Epoch 080 | Loss 0.012 | Train 1.000 Val 0.732 Test 0.772\n",
      "Epoch 100 | Loss 0.012 | Train 1.000 Val 0.736 Test 0.776\n",
      "Epoch 120 | Loss 0.010 | Train 1.000 Val 0.744 Test 0.780\n",
      "Epoch 140 | Loss 0.011 | Train 1.000 Val 0.736 Test 0.777\n",
      "Epoch 160 | Loss 0.009 | Train 1.000 Val 0.732 Test 0.779\n",
      "Epoch 180 | Loss 0.012 | Train 1.000 Val 0.742 Test 0.784\n",
      "Epoch 200 | Loss 0.009 | Train 1.000 Val 0.734 Test 0.770\n",
      "\n",
      "TRIMMED (GCN on cosine kept graph + guards)\n",
      "train: 0.9929\n",
      "val: 0.7700\n",
      "test: 0.7720\n",
      "epochs: 200\n",
      "train_time: 2.4452\n",
      "avg_epoch_time: 0.0122\n",
      "best_val: 0.7700\n",
      "Total time (incl. trimming): 2.49s\n"
     ]
    }
   ],
   "source": [
    "# Purpose: trim edges using the chosen method and guards, then train the same model on the trimmed graph\n",
    "\n",
    "set_seed(0)\n",
    "new_edge_index, trim_time, stats = trim_with_guards(\n",
    "    data,\n",
    "    method=METHOD,\n",
    "    keep_rate=K_KEEP,\n",
    "    hub_percent=HUB_P,\n",
    "    reconnect_mode=RECONNECT,\n",
    "    effective_keep_cap=EFF_CAP\n",
    ")\n",
    "print(\"Trim stats:\", stats, f\"| trim_time: {trim_time:.2f}s\")\n",
    "\n",
    "# build a new Data with the trimmed edges\n",
    "from torch_geometric.data import Data\n",
    "trimmed = Data(\n",
    "    x=data.x, y=data.y, edge_index=new_edge_index,\n",
    "    train_mask=data.train_mask, val_mask=data.val_mask, test_mask=data.test_mask\n",
    ").to(device)\n",
    "\n",
    "set_seed(0)\n",
    "trim_model = GCN(dataset.num_node_features, HIDDEN, dataset.num_classes, DROPOUT)\n",
    "trim = train_model(trim_model, trimmed, epochs=EPOCHS, lr=LR, wd=WD, log_every=20)\n",
    "\n",
    "print(\"\\nTRIMMED (GCN on\", METHOD, \"kept graph + guards)\")\n",
    "for k, v in trim.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")\n",
    "print(f\"Total time (incl. trimming): {trim['train_time'] + trim_time:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1b8e264-a749-45fc-9cdf-a26ead0178da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUMMARY ===\n",
      "Keep-Rate target: 80%  |  Hub-preserve: 10%\n",
      "LCC% original: 91.77%   LCC% trimmed: 90.77%\n",
      "Baseline Test Acc: 0.8080   Trimmed Test Acc: 0.7720   Δ = -0.0360\n",
      "Avg epoch time (baseline): 0.0130s   (trimmed): 0.0122s   ~-6.0% change\n",
      "Total train time (baseline): 2.61s   (trimmed): 2.45s\n",
      "Total incl. trimming: baseline=2.61s  trimmed=2.49s\n"
     ]
    }
   ],
   "source": [
    "# Purpose: print a clear summary comparing baseline and trimmed with percentages\n",
    "# This cell assumes K_KEEP, HUB_P, base, trim, data, stats, trim_time all exist\n",
    "\n",
    "def pct(a, b):\n",
    "    return 0.0 if a == 0 else 100.0 * (b - a) / a\n",
    "\n",
    "print(\"=== SUMMARY ===\")\n",
    "print(f\"Keep-Rate target: {int(K_KEEP*100)}%  |  Hub-preserve: {int(HUB_P*100)}%\")\n",
    "print(f\"LCC% original: {lcc_percent(data)[0]:.2f}%   LCC% trimmed: {stats['LCC_percent']:.2f}%\")\n",
    "print(f\"Baseline Test Acc: {base['test']:.4f}   Trimmed Test Acc: {trim['test']:.4f}   Δ = {trim['test']-base['test']:.4f}\")\n",
    "print(\n",
    "    f\"Avg epoch time (baseline): {base['avg_epoch_time']:.4f}s   (trimmed): {trim['avg_epoch_time']:.4f}s   \"\n",
    "    f\"~{pct(base['avg_epoch_time'], trim['avg_epoch_time']):+.1f}% change\"\n",
    ")\n",
    "print(f\"Total train time (baseline): {base['train_time']:.2f}s   (trimmed): {trim['train_time']:.2f}s\")\n",
    "print(f\"Total incl. trimming: baseline={base['train_time']:.2f}s  trimmed={(trim['train_time']+trim_time):.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ce73a5d-f356-4516-afe0-182cdae86179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-running with METHOD: jaccard K_KEEP: 0.9\n",
      "Trim stats: {'orig_undirected': 5278, 'kept_undirected': 4870, 'keep_rate_target': 0.9, 'keep_rate_effective': 0.9226979916635089, 'LCC_percent': 91.3589364844904, 'components': 104} | trim_time: 0.03s\n",
      "Epoch 001 | Loss 1.940 | Train 0.807 Val 0.522 Test 0.526\n",
      "Epoch 020 | Loss 0.012 | Train 1.000 Val 0.762 Test 0.770\n",
      "Epoch 040 | Loss 0.013 | Train 1.000 Val 0.756 Test 0.781\n",
      "Epoch 060 | Loss 0.017 | Train 1.000 Val 0.750 Test 0.789\n",
      "Epoch 080 | Loss 0.013 | Train 1.000 Val 0.744 Test 0.788\n",
      "Epoch 100 | Loss 0.013 | Train 1.000 Val 0.752 Test 0.803\n",
      "Epoch 120 | Loss 0.010 | Train 1.000 Val 0.742 Test 0.800\n",
      "Epoch 140 | Loss 0.012 | Train 1.000 Val 0.744 Test 0.793\n",
      "Epoch 160 | Loss 0.011 | Train 1.000 Val 0.740 Test 0.796\n",
      "Epoch 180 | Loss 0.012 | Train 1.000 Val 0.748 Test 0.800\n",
      "Epoch 200 | Loss 0.010 | Train 1.000 Val 0.750 Test 0.790\n",
      "\n",
      "TRIMMED (GCN on jaccard kept graph + guards)\n",
      "train: 0.9929\n",
      "val: 0.7740\n",
      "test: 0.7900\n",
      "epochs: 200\n",
      "train_time: 2.5210\n",
      "avg_epoch_time: 0.0126\n",
      "best_val: 0.7740\n",
      "Total time (incl. trimming): 2.55s\n",
      "\n",
      "=== SUMMARY (rerun) ===\n",
      "Keep-Rate target: 90%  |  Hub-preserve: 10%\n",
      "LCC% original: 91.77%   LCC% trimmed: 91.36%\n",
      "Baseline Test Acc: 0.8080   Trimmed Test Acc: 0.7900   Δ = -0.0180\n",
      "Avg epoch time (baseline): 0.0130s   (trimmed): 0.0126s   ~-3.1% change\n",
      "Total train time (baseline): 2.61s   (trimmed): 2.52s\n",
      "Total incl. trimming: baseline=2.61s  trimmed=2.55s\n"
     ]
    }
   ],
   "source": [
    "# Purpose: quick reruns by changing METHOD or K_KEEP without touching earlier cells\n",
    "# Example: switch to Jaccard at 0.90 keep\n",
    "\n",
    "METHOD = \"jaccard\"\n",
    "K_KEEP = 0.90\n",
    "print(\"Re-running with METHOD:\", METHOD, \"K_KEEP:\", K_KEEP)\n",
    "\n",
    "set_seed(0)\n",
    "new_edge_index, trim_time, stats = trim_with_guards(\n",
    "    data,\n",
    "    method=METHOD,\n",
    "    keep_rate=K_KEEP,\n",
    "    hub_percent=HUB_P,\n",
    "    reconnect_mode=RECONNECT,\n",
    "    effective_keep_cap=EFF_CAP\n",
    ")\n",
    "print(\"Trim stats:\", stats, f\"| trim_time: {trim_time:.2f}s\")\n",
    "\n",
    "trimmed = type(data)(\n",
    "    x=data.x, y=data.y, edge_index=new_edge_index,\n",
    "    train_mask=data.train_mask, val_mask=data.val_mask, test_mask=data.test_mask\n",
    ").to(device)\n",
    "\n",
    "set_seed(0)\n",
    "trim_model = GCN(dataset.num_node_features, HIDDEN, dataset.num_classes, DROPOUT)\n",
    "trim = train_model(trim_model, trimmed, epochs=EPOCHS, lr=LR, wd=WD, log_every=20)\n",
    "\n",
    "print(\"\\nTRIMMED (GCN on\", METHOD, \"kept graph + guards)\")\n",
    "for k, v in trim.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")\n",
    "print(f\"Total time (incl. trimming): {trim['train_time'] + trim_time:.2f}s\")\n",
    "\n",
    "# summary again\n",
    "print(\"\\n=== SUMMARY (rerun) ===\")\n",
    "print(f\"Keep-Rate target: {int(K_KEEP*100)}%  |  Hub-preserve: {int(HUB_P*100)}%\")\n",
    "print(f\"LCC% original: {lcc_percent(data)[0]:.2f}%   LCC% trimmed: {stats['LCC_percent']:.2f}%\")\n",
    "print(f\"Baseline Test Acc: {base['test']:.4f}   Trimmed Test Acc: {trim['test']:.4f}   Δ = {trim['test']-base['test']:.4f}\")\n",
    "print(\n",
    "    f\"Avg epoch time (baseline): {base['avg_epoch_time']:.4f}s   (trimmed): {trim['avg_epoch_time']:.4f}s   \"\n",
    "    f\"~{(100.0*(trim['avg_epoch_time']-base['avg_epoch_time'])/base['avg_epoch_time']):+.1f}% change\"\n",
    ")\n",
    "print(f\"Total train time (baseline): {base['train_time']:.2f}s   (trimmed): {trim['train_time']:.2f}s\")\n",
    "print(f\"Total incl. trimming: baseline={base['train_time']:.2f}s  trimmed={(trim['train_time']+trim_time):.2f}s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphspar (conda)",
   "language": "python",
   "name": "graphspar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
